agent:
  env_file: ".env.local"
  instructions_file: src/prompts/system.txt
  greeting: "Hello! Welcome to Furlenco. My name is Sasha and I'm here to assist you. For a personalized experience can I please have your first name?"
  goodbye: "Goodbye! Have a great day!"
  default_participant_identity: "identity-qfXx"
  use_eou: false                                      # livekit turn detection
  use_background_noise_removal: true                  # uses Krisp BVC noise cancellation. If self-hosting, set as false
  use_background_audio: false                         # plays office background audio and keyboard typing sound while the agent speaks
  allow_interruptions: True                           # reset tts on user iterruption
  triage:
    instructions_file: src/prompts/triage_system_prompt.txt
    greeting: "Hello! Welcome to Furlenco. My name is Sasha and I'm here to assist you. For a personalized experience can I please have your first name?"
    voice: "Ruth"
  sales:
    instructions_file: src/prompts/sales_system_prompt.txt
    voice: "Danielle"
  service:
    instructions_file: src/prompts/service_system_prompt.txt
    voice: "Kajal"

stt:
  use_local: false
  aws_transcribe:
    language: "en-US"  
  whisper:
    language: "en"                      
    model: "deepdml/faster-whisper-large-v3-turbo-ct2" 
    device: "cuda"                     
    compute_type: "float16"             
    model_cache_directory: "/data/models_cache"  
    warmup_audio: "data/warmup_audio.wav"  

llm:
  use_local: false
  aws_bedrock:
    model: "anthropic.claude-3-haiku-20240307-v1:0"   # "anthropic.claude-3-5-sonnet-20240620-v1:0"
    temperature: 0.8
  ollama:
    base_url: "http://localhost:11434/v1" 
    model: "qwen2.5vl:7b-q4_K_M"                 
    temperature: 0.4                  
    api_key: "NULL"                      
    parallel_tool_calls: false
    tool_choice: "auto"

tts:
  use_local: false
  aws_polly:
    voice: "Danielle"
    speech_engine: "generative"
    language: "en-US"   

vad:
  min_speech_duration: 0.50             # Minimum duration (seconds) for speech detection
  min_silence_duration: 1.50            # Minimum silence duration (seconds) to detect end of speech
  prefix_padding_duration: 0.5          # Padding duration (seconds) before detected speech
  max_buffered_speech: 60.0             # Maximum duration (seconds) of buffered speech
  activation_threshold: 0.5             # Threshold for voice activation detection
  force_cpu: false                      # Force VAD to run on CPU instead of GPU
  sample_rate: 16000  

vision:
  use: true                            
  video_frame_interval: 0.2   

memory:
  use: false                             
  dir: "data/memory_store"              
  load_last_n: 6       

embedding:
  vllm_model_name: "mixedbread-ai/mxbai-embed-large-v1"                             

worker:
  job_memory_warn_mb: 10000              
  load_threshold: 1.0                   
  job_memory_limit_mb: 20000            

logging:
  level: "DEBUG"                         
  file: "logs/app.log"                